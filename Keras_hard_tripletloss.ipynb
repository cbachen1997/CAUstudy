{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Keras_hard_tripletloss.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbachen1997/CAUstudy/blob/Keras_TripletLoss/Keras_hard_tripletloss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fIpYXqMZJSx_",
        "colab": {}
      },
      "source": [
        "#挂载谷歌云盘\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "####google云盘授权#####\n",
        "##每个notebook执行一次###\n",
        "__author__='CBA'\n",
        "from google.colab import drive\n",
        "\n",
        "#增加PyDrive操作库\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "#授权登录\n",
        "auth.authenticate_user()\n",
        "gauth=GoogleAuth()\n",
        "gauth.credentials=GoogleCredentials.get_application_default()\n",
        "drive=GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PGA6CbR-J1l8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "2253558c-4d38-4138-c8f5-7deae839ebf5"
      },
      "source": [
        "#更改运行目录\n",
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/AndrewNgTest/Keras_tripletloss\")\n",
        "print (os.path.abspath('.')) #获取当前工作目录路径\n",
        "print(os.listdir('.'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/AndrewNgTest/Keras_tripletloss\n",
            "['inception_blocks_v2.py', 'train_face.h5', 'test_happy.h5', 'fr_utils.py', 'train_happy.h5', '__pycache__', 'FRmodel.png', 'images', 'weights', 'Triplet_loss_KERAS_semi_hard_from_TF.ipynb', 'Triplet_loss_KERAS_semi_hard_from_TF (1).ipynb', 'Keras_tripletloss.ipynb', 'Keras_tripletloss (1).ipynb']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rbr2gdz0LY7M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8d107592-21ee-424f-e856-dd6c45c5d393"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.engine.topology import Layer\n",
        "from keras import backend as K\n",
        "import h5py\n",
        "\n",
        "#模型绘制\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "#数据格式(m,c,w,h)\n",
        "K.set_image_data_format('channels_first')\n",
        "\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import fr_utils\n",
        "from inception_blocks_v2 import *#在这 o\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline \n",
        "#plot后直接画图，不用再show\n",
        "%load_ext autoreload\n",
        "#自动装入所有模块\n",
        "%autoreload 2\n",
        "#每运行一个cell都会重新import所有module\n",
        "np.set_printoptions(threshold=1000000)#np.nan输出所有的值，不要省略号，报错未知"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "41B6h9kSNYwp",
        "colab": {}
      },
      "source": [
        "#调用inception_blocks_v2\n",
        "FRmodel = faceRecoModel(input_shape=(3,96,96))\n",
        "# FRmodel=testModel(input_shape=(3,96,96))\n",
        "#输入(m,3,96,96)\n",
        "#输出(m,128)向量\n",
        "#打印模型的总参数数量\n",
        "# print(\"参数数量：\" + str(FRmodel.count_params()))"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w59MCnJ3PZMk",
        "colab": {}
      },
      "source": [
        "#绘制模型\n",
        "# %matplotlib inline\n",
        "# plot_model(FRmodel, to_file='FRmodel.png',show_shapes=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7B9Ak1ibhjGO",
        "colab": {}
      },
      "source": [
        "#人脸数据集的输入\n",
        "def load_face():\n",
        "  train_dataset = h5py.File('train_face.h5', \"r\")\n",
        "  train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "  train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "  train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "\n",
        "  return train_set_x_orig, train_set_y_orig"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A1Of3wVk1kj5",
        "colab": {}
      },
      "source": [
        "train_set_x_orig, train_set_y_orig=load_face()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OHBFtqzH1soQ",
        "colab": {}
      },
      "source": [
        "# train_set_y_orig[0][1].decode('utf-8')\n",
        "namecount = {'sebastiano': 68, 'felix': 66, 'benoit': 51, 'arnaud': 31, 'bertrand': 61, 'kian': 39, 'younes': 52, 'dan': 58}\n",
        "# nameindex = {'sebastiano': 0, 'felix': 1, 'benoit': 2, 'arnaud': 3, 'bertrand': 4, 'kian': 5, 'younes': 6, 'dan': 7}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dNnPeCILmqap",
        "colab": {}
      },
      "source": [
        "#建立索引函数\n",
        "def create_index(train_set_y):\n",
        "#=============获取数据集中人的集合================\n",
        "  name=np.unique(train_set_y)\n",
        "  #解码获得姓名列表\n",
        "  namelist=[]\n",
        "  for i in name:\n",
        "    namelist.append(i.decode('utf8'))\n",
        "#==============获取每个人的数据索引=========================\n",
        "  #初始化\n",
        "  person_index=locals()\n",
        "  for i,name in enumerate(namelist):\n",
        "    person_index[name]=[]\n",
        "  for j in range(train_set_y.shape[1]):\n",
        "    name=train_set_y[0][j].decode('utf-8')\n",
        "    person_index[name].append(j)\n",
        "  return namelist,person_index"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GpI2KaNXs0lE",
        "colab": {}
      },
      "source": [
        "#随机抽取batch\n",
        "def sample_people(namelist,person_index,num_person,num_picture):\n",
        "  #随机选定指定数量的人数\n",
        "  total=num_person*num_picture\n",
        "  person=random.sample(namelist,num_person)\n",
        "  #从人的列表中随机抽5个\n",
        "  index=locals()\n",
        "  for i in person:\n",
        "    temp=[]\n",
        "    index[i]=random.sample(list(person_index[i]),num_picture)\n",
        "  return person,index,total"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x_RQ4aC51WSG",
        "colab": {}
      },
      "source": [
        "#计算batch中各元素的embedding编码\n",
        "def calculate_embedding(train_set_x,model,namelist,person_index,numperson,numpicture):\n",
        "  person,index,total=sample_people(namelist=namelist,person_index=person_index,num_person=numperson,num_picture=numpicture)\n",
        "  embed_array=np.zeros((total,128))\n",
        "  embed_index=np.zeros((1,total))\n",
        "  for num,name in enumerate(person):\n",
        "    #获取每个人的数字\n",
        "    temp=index[name]\n",
        "    for num_index,j in enumerate(temp):\n",
        "      #获取每个人对应的影像\n",
        "      # print(j)\n",
        "      img=train_set_x[j]\n",
        "      img=np.around(np.transpose(img,(2,0,1))/255.0,decimals=12)\n",
        "      x_train=np.array([img])#shape=(1,3,96,96)\n",
        "      #投影到embedding空间\n",
        "      embedding=model.predict_on_batch(x_train)\n",
        "      embed_array[5*num+num_index,:]=embedding\n",
        "      embed_index[0,5*num+num_index]=j\n",
        "  return embed_array,embed_index\n",
        "  #获得一个(5,5,128)的编码矩阵，(x,y,vector)，x代表人，y代表人对应的抽出来的图片，vector为图片经过embedding得到的结果\n",
        "  #embed_index为编码对应的图像索引"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c1BCePE_TFJq",
        "colab": {}
      },
      "source": [
        "#计算距离矩阵\n",
        "from scipy.spatial.distance import pdist\n",
        "from scipy.spatial.distance import squareform\n",
        "def D_mat(X):\n",
        "  \"\"\"\n",
        "  X是batch中所有的embedding\n",
        "  \"\"\"\n",
        "  #距离矩阵计算方法https://zhuanlan.zhihu.com/p/77034615\n",
        "  # print(X.shape)\n",
        "  # A是一个向量矩阵：euclidean代表欧式距离\n",
        "  distA=pdist(X,metric='euclidean') \n",
        "  distB = squareform(distA)\n",
        "  return distB\n",
        "#获取最大距离\n",
        "def get_hard_positive(Dmat,embed_index,anchor,num_per_person):\n",
        "  range_=int(anchor/num_per_person)\n",
        "  remainder=anchor%num_per_person\n",
        "  temp=Dmat\n",
        "  #positive矩阵\n",
        "  p_mat=Dmat[range_*5:range_*5+5,range_*5:range_*5+5]\n",
        "  #negative矩阵\n",
        "  n_mat=np.delete(Dmat[range_*5:range_*5+5,:],[i for i in range(range_*5,range_*5+5)],1)\n",
        "#===========================获取hard_positive===================================\n",
        "  # print(p_mat)\n",
        "  hp=np.argmax(p_mat[remainder][:])#p_mat中hard_positive的位置\n",
        "  # print(p_mat[remainder][:])\n",
        "  # print(hp)\n",
        "  hp_index=5*range_+hp\n",
        "  # print(hp_index)\n",
        "  hp_index=int(embed_index[:,hp_index])\n",
        "#===========================获取hard_negative===================================\n",
        "  np_=np.argmin(n_mat[remainder][:])\n",
        "  # print(n_mat[remainder][:])\n",
        "  if (np_+5)>5*range_+4:\n",
        "    np_index=np_+5\n",
        "  else:\n",
        "    np_index=np_\n",
        "  # print(np_index)\n",
        "  np_index=int(embed_index[:,np_index])\n",
        "#============================获得一组困难三元组\n",
        "  anchor_index=int(embed_index[:,anchor])\n",
        "  return [anchor_index,hp_index,np_index]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z_Jg0BgaBiDT",
        "colab": {}
      },
      "source": [
        "#从batch中构建困难三元组\n",
        "def get_hard_triplet(embed_array,embed_index):\n",
        "  #获取距离矩阵\n",
        "  distance=D_mat(embed_array)\n",
        "  #三元组编号数组\n",
        "  hard_triplet=[]\n",
        "  #构建PK个三元组，P为人数，K为每人选取照片个数\n",
        "  for i in range(embed_array.shape[0]):\n",
        "    hard_triplet.append(get_hard_positive(distance,embed_index,anchor=i,num_per_person=5))\n",
        "  return hard_triplet"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jIZPNhLzf6l3",
        "colab": {}
      },
      "source": [
        "def triplet_loss(y_pred,alpha):\n",
        "  \"\"\" \n",
        "  参数：\n",
        "      y_true -- true标签，当你在Keras里定义了一个损失函数的时候需要它，但是这里不需要。\n",
        "      y_pred -- 列表类型，包含了如下参数：\n",
        "          anchor -- 给定的“anchor”图像的编码，维度为(None,128)\n",
        "          positive -- “positive”图像的编码，维度为(None,128)\n",
        "          negative -- “negative”图像的编码，维度为(None,128)\n",
        "      alpha -- 超参数，阈值\n",
        "  \n",
        "  返回：\n",
        "      loss -- 实数，损失的值\n",
        "  \"\"\"\n",
        "  # print(y_pred)\n",
        "  #获取anchor, positive, negative的图像编码\n",
        "  anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
        "  #第一步：计算\"anchor\" 与 \"positive\"之间编码的距离，这里需要使用axis=-1\n",
        "  pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1,keepdims=True)#二范数，-1代表倒数第一个维度即128\n",
        "  #第二步：计算\"anchor\" 与 \"negative\"之间编码的距离，这里需要使用axis=-1\n",
        "  neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1,keepdims=True)\n",
        "  #第三步：减去之前的两个距离，然后加上alpha\n",
        "  basic_loss = tf.add(tf.subtract(pos_dist,neg_dist),tf.constant(alpha))\n",
        "  #通过取带零的最大值和对训练样本的求和来计算整个公式\n",
        "  loss = tf.maximum(basic_loss,0)\n",
        "  # loss = basic_loss\n",
        "  # print(loss)\n",
        "  return loss\n"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8AO6pqG0p8dS",
        "colab": {}
      },
      "source": [
        "#构建困难三元组流程\n",
        "def process_triplet(train_set_x,train_set_y,model,num_person_,num_picture_):\n",
        "  #建立索引和名字列表\n",
        "  namelist,person_index=create_index(train_set_y)\n",
        "  #随机抽取batch\n",
        "  person,index,total=sample_people(namelist,person_index=person_index,num_person=num_person_,num_picture=num_picture_)#修改此处来修改batchsize\n",
        "  #计算batch中所有图片的编码\n",
        "  embed_array,embed_index=calculate_embedding(train_set_x,model,namelist,person_index,numperson=num_person_,numpicture=num_picture_)\n",
        "  #获得困难三元组\n",
        "  hard_triplet=get_hard_triplet(embed_array,embed_index)\n",
        "  return hard_triplet,total"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iUyTevB_a6j8",
        "colab": {}
      },
      "source": [
        "#获取三元组数据,及标签\n",
        "def get_triplet_data(triplet):\n",
        "  y=np.zeros((3,3,96,96))\n",
        "  labels=[]\n",
        "  flag=0\n",
        "  for i in triplet:\n",
        "    # print(np.transpose(train_set_x_orig[i],[2,0,1]).shape\n",
        "    y[flag,:]=np.transpose(train_set_x_orig[i],[2,0,1])\n",
        "    flag+=1\n",
        "  return y"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZwkhpJZoZuJ9",
        "colab": {}
      },
      "source": [
        "def create_train_model(FRmodel,alpha):\n",
        "  y_pred=[]\n",
        "  anchor_input = Input((3,96,96)) \n",
        "  positive_input = Input((3,96,96))\n",
        "  negative_input = Input((3,96,96))\n",
        "  # FRmodel = faceRecoModel(input_shape=(3,96,96))\n",
        "  # an = Model(anchor_input, FRmodel(anchor_input))\n",
        "  anchor_out = Model(anchor_input, FRmodel(anchor_input))\n",
        "  positive_out = Model(positive_input, FRmodel(positive_input))\n",
        "  negative_out = Model(negative_input, FRmodel(negative_input))\n",
        "  # anchor_out = FRmodel(anchor_input)\n",
        "  # positive_out = FRmodel(positive_input)\n",
        "  # negative_out = FRmodel(negative_input)\n",
        "  y_pred.append(anchor_out.output)\n",
        "  y_pred.append(positive_out.output)\n",
        "  y_pred.append(negative_out.output)\n",
        "\n",
        "  loss = Lambda(lambda x: triplet_loss(x, alpha), output_shape=[1])(y_pred)\n",
        "  # y_true=np.zeros((total,3)).tolist()\n",
        "  # alpha=0.2\n",
        "  return Model(inputs = [anchor_input,positive_input,negative_input], outputs=loss)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lhlEE6j_h0bY",
        "colab": {}
      },
      "source": [
        "#训练模型\n",
        "def train_model(FRmodel,alpha=0.2):\n",
        "  #开始时间\n",
        "  tic = time.clock()\n",
        "  num_times=10\n",
        "  model=create_train_model(FRmodel,alpha)\n",
        "  # model.add_loss(model.output)\n",
        "  model.compile(optimizer = 'adam', loss=lambda t,p:p, metrics = 'accuracy')\n",
        "  # model.add_loss(triplet_loss())\n",
        "  '''\n",
        "  func(y_t, y_pred):\n",
        "    y_t 随机 无用 \n",
        "    loss = y_pred\n",
        "    return loss\n",
        "  '''\n",
        "  model.summary()\n",
        "  for i in range(num_times):\n",
        "    #获得一个batch的困难三元组\n",
        "    print('正在训练第'+str(i)+'个batch')\n",
        "    hard_tri,total=process_triplet(train_set_x_orig,train_set_y_orig,FRmodel,num_person_=8,num_picture_=10)\n",
        "    # y_pred=[]\n",
        "    y_label=np.zeros((total,1))#y用不着\n",
        "    # y_label=np.array(y_label)\n",
        "    flags=0\n",
        "    x_input = [ np.zeros((total, 3, 96, 96)), np.zeros((total, 3, 96, 96)), np.zeros((total, 3, 96, 96)) ]\n",
        "    #构建输入的x\n",
        "    for i in hard_tri:\n",
        "      triplet = i\n",
        "      triplet = list(map(int, triplet))\n",
        "      y=get_triplet_data(triplet)#(3,3,96,96)\n",
        "      # y=np.array(y)\n",
        "      for idx in range(3):\n",
        "        x_input[idx][flags] = y[idx]\n",
        "      # y_pred.append(y)\n",
        "      flags+=1\n",
        "    #y_pred为x，y_label为y\n",
        "    \n",
        "    model.fit(x=x_input,y=y_label,batch_size=total,epochs=5)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y2gATYCQnA_A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5186db0d-c86c-4fed-eb0c-53dab886410c"
      },
      "source": [
        "#开始时间\n",
        "tic = time.clock()\n",
        "\n",
        "#加载权值\n",
        "# fr_utils.load_weights_from_FaceNet(FRmodel)\n",
        "#模型训练\n",
        "# FRmodel.compile(optimizer='adam')\n",
        "train_model(FRmodel,alpha=0.3) \n",
        "#结束时间\n",
        "toc = time.clock()\n",
        "\n",
        "#计算时差\n",
        "minium = toc-tic\n",
        "\n",
        "print(\"执行了：\" + str(int(minium / 60)) + \"分\" + str(int(minium%60)) + \"秒\")"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_251\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_152 (InputLayer)          [(None, 3, 96, 96)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_153 (InputLayer)          [(None, 3, 96, 96)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_154 (InputLayer)          [(None, 3, 96, 96)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "FaceRecoModel (Functional)      (None, 128)          3743280     input_152[0][0]                  \n",
            "                                                                 input_153[0][0]                  \n",
            "                                                                 input_154[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_77 (Lambda)              (None, 1)            0           FaceRecoModel[0][0]              \n",
            "                                                                 FaceRecoModel[1][0]              \n",
            "                                                                 FaceRecoModel[2][0]              \n",
            "==================================================================================================\n",
            "Total params: 3,743,280\n",
            "Trainable params: 3,733,968\n",
            "Non-trainable params: 9,312\n",
            "__________________________________________________________________________________________________\n",
            "正在训练第0个batch\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.2789 - accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 0.1965 - accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 0.1536 - accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.1356 - accuracy: 0.9875\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.1454 - accuracy: 0.9875\n",
            "正在训练第1个batch\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.3724 - accuracy: 0.8625\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 308ms/step - loss: 0.1933 - accuracy: 0.9750\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.1163 - accuracy: 0.9875\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.0407 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.0224 - accuracy: 1.0000\n",
            "正在训练第2个batch\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 0.2701 - accuracy: 0.9250\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.1932 - accuracy: 0.9625\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 0.1426 - accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.1226 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 0.0472 - accuracy: 1.0000\n",
            "正在训练第3个batch\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 0.1742 - accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.1695 - accuracy: 0.9875\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 0.1626 - accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 310ms/step - loss: 0.1539 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 0.1344 - accuracy: 1.0000\n",
            "正在训练第4个batch\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 301ms/step - loss: 0.1363 - accuracy: 0.9375\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 0.1318 - accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 0.1289 - accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.1126 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 0.0456 - accuracy: 1.0000\n",
            "正在训练第5个batch\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 0.1559 - accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.1267 - accuracy: 0.9875\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.0429 - accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 0.1248 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 0.1165 - accuracy: 1.0000\n",
            "正在训练第6个batch\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 0.1619 - accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.1478 - accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 0.1051 - accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 0.0354 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 0.0362 - accuracy: 1.0000\n",
            "正在训练第7个batch\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 303ms/step - loss: 0.2201 - accuracy: 0.8875\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 0.1209 - accuracy: 0.9625\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.0404 - accuracy: 0.9625\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 0.0263 - accuracy: 0.9625\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 0.0275 - accuracy: 0.9750\n",
            "正在训练第8个batch\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 331ms/step - loss: 0.1167 - accuracy: 0.9250\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 0.0475 - accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.0422 - accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.0452 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 0.0440 - accuracy: 1.0000\n",
            "正在训练第9个batch\n",
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 306ms/step - loss: 0.0318 - accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 0.0295 - accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 337ms/step - loss: 0.0299 - accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 0.0270 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 343ms/step - loss: 0.0255 - accuracy: 1.0000\n",
            "执行了：0分45秒\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2i7jd7ep6ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FRmodel.save('my_FRmodel.h5')\n",
        "#储存模型"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0hJUvUwioKUV",
        "colab": {}
      },
      "source": [
        "database = {}\n",
        "database[\"danielle\"] = fr_utils.img_to_encoding(\"images/danielle.png\", FRmodel)\n",
        "database[\"younes\"] = fr_utils.img_to_encoding(\"images/younes.jpg\", FRmodel)\n",
        "database[\"tian\"] = fr_utils.img_to_encoding(\"images/tian.jpg\", FRmodel)\n",
        "database[\"andrew\"] = fr_utils.img_to_encoding(\"images/andrew.jpg\", FRmodel)\n",
        "database[\"kian\"] = fr_utils.img_to_encoding(\"images/kian.jpg\", FRmodel)\n",
        "database[\"dan\"] = fr_utils.img_to_encoding(\"images/dan.jpg\", FRmodel)\n",
        "database[\"sebastiano\"] = fr_utils.img_to_encoding(\"images/sebastiano.jpg\", FRmodel)\n",
        "database[\"bertrand\"] = fr_utils.img_to_encoding(\"images/bertrand.jpg\", FRmodel)\n",
        "database[\"kevin\"] = fr_utils.img_to_encoding(\"images/kevin.jpg\", FRmodel)\n",
        "database[\"felix\"] = fr_utils.img_to_encoding(\"images/felix.jpg\", FRmodel)\n",
        "database[\"benoit\"] = fr_utils.img_to_encoding(\"images/benoit.jpg\", FRmodel)\n",
        "database[\"arnaud\"] = fr_utils.img_to_encoding(\"images/arnaud.jpg\", FRmodel)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXcqFB4Bwa3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#载入模型\n",
        "from keras.models import  load_model\n",
        "testmodel=load_model('my_FRmodel.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVGbh3lxw8KJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def verify(image_path, identity, database, model):\n",
        "    \"\"\"\n",
        "    对“identity”与“image_path”的编码进行验证。\n",
        "    \n",
        "    参数：\n",
        "        image_path -- 摄像头的图片。\n",
        "        identity -- 字符类型，想要验证的人的名字。\n",
        "        database -- 字典类型，包含了成员的名字信息与对应的编码。\n",
        "        model -- 在Keras的模型的实例。\n",
        "        \n",
        "    返回：\n",
        "        dist -- 摄像头的图片与数据库中的图片的编码的差距。\n",
        "        is_open_door -- boolean,是否该开门。\n",
        "    \"\"\"\n",
        "    #第一步：计算图像的编码，使用fr_utils.img_to_encoding()来计算。\n",
        "    encoding = fr_utils.img_to_encoding(image_path, model)\n",
        "    \n",
        "    #第二步：计算与数据库中保存的编码的差距\n",
        "    dist = np.linalg.norm(encoding - database[identity])\n",
        "    \n",
        "    #第三步：判断是否打开门\n",
        "    if dist < 0.7:\n",
        "        print(\"欢迎 \" + str(identity) + \"回家！\")\n",
        "        is_door_open = True\n",
        "    else:\n",
        "        print(\"经验证，您与\" + str(identity) + \"不符！\")\n",
        "        is_door_open = False\n",
        "    \n",
        "    return dist, is_door_open"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDpcegZxw9y-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path=\"images/camera_2.jpg\"\n",
        "verify(path,\"benoit\",database,FRmodel)\n",
        "img=plt.imread(path)\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6g-VEOMx2Ms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def who_is_it(image_path, database,model):\n",
        "    \"\"\"\n",
        "    根据指定的图片来进行人脸识别\n",
        "    \n",
        "    参数：\n",
        "        images_path -- 图像地址\n",
        "        database -- 包含了名字与编码的字典\n",
        "        model -- 在Keras中的模型的实例。\n",
        "        \n",
        "    返回：\n",
        "        min_dist -- 在数据库中与指定图像最相近的编码。\n",
        "        identity -- 字符串类型，与min_dist编码相对应的名字。\n",
        "    \"\"\"\n",
        "    #步骤1：计算指定图像的编码，使用fr_utils.img_to_encoding()来计算。\n",
        "    encoding = fr_utils.img_to_encoding(image_path, model)\n",
        "    \n",
        "    #步骤2 ：找到最相近的编码\n",
        "    ## 初始化min_dist变量为足够大的数字，这里设置为100\n",
        "    min_dist = 100\n",
        "    \n",
        "    ## 遍历数据库找到最相近的编码\n",
        "    for (name,db_enc) in database.items():\n",
        "        ### 计算目标编码与当前数据库编码之间的L2差距。\n",
        "        dist = np.linalg.norm(encoding - db_enc)\n",
        "        \n",
        "        ### 如果差距小于min_dist，那么就更新名字与编码到identity与min_dist中。\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            identity = name\n",
        "    \n",
        "    # 判断是否在数据库中\n",
        "    if min_dist > 0.7:\n",
        "        print(\"抱歉，您的信息不在数据库中。\")\n",
        "        \n",
        "    else:\n",
        "        print(\"姓名\" + str(identity) + \"  差距：\" + str(min_dist))\n",
        "    \n",
        "    return min_dist, identity"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugfEvM3z2N3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(5):\n",
        "  path = \"images/camera_\"+str(i) + \".jpg\"\n",
        "  who_is_it(path, database, FRmodel)\n",
        "  img=plt.imread(path)\n",
        "  plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erEfH_TW21KT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 165,
      "outputs": []
    }
  ]
}