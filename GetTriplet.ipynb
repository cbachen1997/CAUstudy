{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GetTriplet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNoB9qyBVZFbU+yUjxNPXtj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbachen1997/CAUstudy/blob/master/GetTriplet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pa4B00vs9QT"
      },
      "source": [
        "#挂载谷歌云盘\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "####google云盘授权#####\n",
        "##每个notebook执行一次###\n",
        "__author__='CBA'\n",
        "from google.colab import drive\n",
        "\n",
        "#增加PyDrive操作库\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "#授权登录\n",
        "auth.authenticate_user()\n",
        "gauth=GoogleAuth()\n",
        "gauth.credentials=GoogleCredentials.get_application_default()\n",
        "drive=GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZwJy98steKF",
        "outputId": "df55c8f7-7835-4619-ec58-d99548098829"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/gdrive/MyDrive/CM\")\n",
        "print (os.path.abspath('.')) #获取当前工作目录路径\n",
        "print(os.listdir('.'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/CM\n",
            "['models.py', 'data_util.py', 'main.py', 'ops.py', 'img', 'roi_patches', 'model.ipynb', 'unlabeled_patches', 'ROI2Patches.ipynb', 'GetTriplet.ipynb']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSbCHLigvbDi"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import *\n",
        "import time\n",
        "import tensorflow.keras as K\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.python.keras.layers.advanced_activations import LeakyReLU\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kUaDYQ4u214"
      },
      "source": [
        "X_train_path = '/content/gdrive/MyDrive/CM/roi_patches/test_X_new.npy'\n",
        "Y_train_path = '/content/gdrive/MyDrive/CM/roi_patches/test_Y_new.npy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_wl2lU4vW5Y"
      },
      "source": [
        "X_train = np.load(X_train_path)\n",
        "Y_train = np.load(Y_train_path)\n",
        "#454个点，231个正例，223个负例"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew6lBKjCvmfZ"
      },
      "source": [
        "X_pos=[]\n",
        "Y_pos=[]\n",
        "X_neg=[]\n",
        "Y_neg=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UulSjvA1vnCE"
      },
      "source": [
        "for i in range(len(Y_train)):\n",
        "  if (Y_train[i]==1):\n",
        "    X_pos.append(X_train[i])\n",
        "    Y_pos.append(Y_train[i])\n",
        "  else:\n",
        "    X_neg.append(X_train[i])\n",
        "    Y_neg.append(Y_train[i])\n",
        "X_pos = np.asarray(X_pos, dtype=np.float32)\n",
        "Y_pos = np.asarray(Y_pos, dtype=np.float32)\n",
        "Y_pos = np.expand_dims(Y_pos,axis=1)\n",
        "X_neg = np.asarray(X_neg, dtype=np.float32)\n",
        "Y_neg = np.asarray(Y_neg, dtype=np.float32)\n",
        "Y_neg = np.expand_dims(Y_neg,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrEMUt37v99h"
      },
      "source": [
        "#简单搭个网络方便跑模型\n",
        "inputshape=(11,11,7)\n",
        "num=25#正负各抽25个\n",
        "alpha=0.05"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "futR15I61sz1"
      },
      "source": [
        "def SimpleNet(input_shape):\n",
        "  \"\"\"\n",
        "  实现一个用于三元组的简单模型\n",
        "  \n",
        "  参数：\n",
        "      input_shape - 输入的数据的维度\n",
        "  返回：\n",
        "      model - 创建的Keras的模型\n",
        "      \n",
        "  \"\"\"\n",
        "\n",
        "  X_input=Input(input_shape)\n",
        "  print(X_input.shape)\n",
        "  X = ZeroPadding2D((3, 3))(X_input)\n",
        "  X = Conv2D(32, (7, 7), strides=(1, 1), name='conv0',kernel_initializer='he_normal')(X)\n",
        "  X = BatchNormalization(axis=3, name='bn0')(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
        "  X = Flatten()(X)#向量化\n",
        "  #最后输出128维向量便于计算度量\n",
        "  X = Dense(128,name='dense_layer')(X)\n",
        "  # L2 normalization\n",
        "  # X = Lambda(lambda  x: K.l2_normalize(x,axis=1))(X)\n",
        "  model = Model(inputs=X_input,outputs=X,name='SimpleModel')\n",
        "\n",
        " \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrVMcDKb8Mly"
      },
      "source": [
        "#三元组部分\n",
        "#随机抽取patch\n",
        "def sampling(datanpy,num=num):\n",
        "  #encode list\n",
        "  list_for_sample=[ i for i in range(datanpy.shape[0])]\n",
        "  samples=random.sample(list_for_sample,num)\n",
        "  samples_npy=np.zeros((num,datanpy.shape[1],datanpy.shape[2],datanpy.shape[3]))\n",
        "  count=0\n",
        "  for i in samples:\n",
        "    samples_npy[count,:,:,:]=datanpy[i,:,:,:]\n",
        "    count+=1\n",
        "  return samples_npy\n",
        "#编码\n",
        "def embedding(datanpy,model):\n",
        "  length  = datanpy.shape[0]\n",
        "  embed_array = np.zeros((datanpy.shape[0],128))\n",
        "  for i in range(length):\n",
        "    embedding=model.predict_on_batch(datanpy)\n",
        "  return embedding\n",
        "#度量计算\n",
        "# from scipy.spatial.distance import pdist\n",
        "# from scipy.spatial.distance import squareform\n",
        "#距离\n",
        "# def D_mat(X):\n",
        "#   \"\"\"\n",
        "#   X: batch中的所有embedding\n",
        "#   \"\"\"\n",
        "#   distA=pdist(X,metric='euclidean') \n",
        "#   distB = squareform(distA)\n",
        "#   return distB\n",
        "#获取hard_triplet\n",
        "from scipy.spatial.distance import euclidean\n",
        "from scipy.spatial.distance import pdist\n",
        "def get_hard_triplet(X_p,X_n,model):\n",
        "  \"\"\"\n",
        "  X_p:原始正例\n",
        "  X_n:原始负例\n",
        "  \"\"\"\n",
        "  num_=X_p.shape[0]\n",
        "  pos_embed=embedding(X_p,model)\n",
        "  neg_embed=embedding(X_n,model)\n",
        "  hard_triplet=np.zeros((num_*2,3,X_p.shape[1],X_p.shape[2],X_p.shape[3]))\n",
        "  count=0\n",
        "  print('构建正例样本困难三元组')\n",
        "  for i in range(num_):\n",
        "    anchor=pos_embed[i,:].reshape((1,-1))\n",
        "    anchor = np.repeat(anchor, num_, axis=0)\n",
        "    #寻找困难正样本,距离最大正\n",
        "    temp_dis=np.sum((anchor-pos_embed)*(anchor-pos_embed),axis=1)\n",
        "    loc_p=temp_dis.argmax()\n",
        "    hard_pos=X_p[loc_p,:,:,:]\n",
        "    #寻找困难负样本，距离最小负\n",
        "    temp_dis=np.sum((anchor-neg_embed)*(anchor-neg_embed),axis=1)\n",
        "    loc_n=temp_dis.argmin()\n",
        "    hard_neg=X_n[loc_n,:,:,:]\n",
        "    count+=1\n",
        "    hard_triplet[i,0,:,:,:]=X_p[i,:,:,:]\n",
        "    hard_triplet[i,1,:,:,:]=hard_pos\n",
        "    hard_triplet[i,2,:,:,:]=hard_neg\n",
        "\n",
        "  print('构建负例样本困难三元组')\n",
        "  for i in range(num_):\n",
        "    anchor=neg_embed[i,:].reshape((1,-1))\n",
        "    anchor = np.repeat(anchor, num_, axis=0)\n",
        "    #寻找正样本,距离最大负\n",
        "    temp_dis=np.sum((anchor-neg_embed)*(anchor-neg_embed),axis=1)\n",
        "    loc_p=temp_dis.argmax()\n",
        "    hard_pos=X_n[loc_p,:,:,:]\n",
        "    #寻找负样本，距离最小正\n",
        "    temp_dis=np.sum((anchor-pos_embed)*(anchor-pos_embed),axis=1)\n",
        "    loc_n=temp_dis.argmin()\n",
        "    hard_neg=X_p[loc_n,:,:,:]\n",
        "    hard_triplet[i,0,:,:,:]=X_p[i,:,:,:]\n",
        "    hard_triplet[i,1,:,:,:]=hard_pos\n",
        "    hard_triplet[i,2,:,:,:]=hard_neg\n",
        "  return hard_triplet\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRUnAjCK9xDg"
      },
      "source": [
        "#构建困难三元组\n",
        "def process_triplet(pos_sample,neg_sample,model,num=num):\n",
        "  #抽样\n",
        "  X_p=sampling(pos_sample,num=num)\n",
        "  X_n=sampling(neg_sample,num=num)\n",
        "  #获取困难三元组\n",
        "  hard_tri=get_hard_triplet(X_p,X_n,model)\n",
        "  return hard_tri"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2p0n_Gt90rp"
      },
      "source": [
        "#三元组损失计算\n",
        "def triplet_loss(triplet,alpha=alpha):\n",
        "  \"\"\"\n",
        "  triplet=三元组\n",
        "  \"\"\"\n",
        "  anchor,positive,negative=triplet[0],triplet[1],triplet[2]\n",
        "  #第一步：计算\"anchor\" 与 \"positive\"之间编码的距离，这里需要使用axis=-1\n",
        "  pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1)#二范数，-1代表倒数第一个维度即128\n",
        "  #第二步：计算\"anchor\" 与 \"negative\"之间编码的距离，这里需要使用axis=-1\n",
        "  neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1)\n",
        "  #第三步：减去之前的两个距离，然后加上alpha\n",
        "  basic_loss = tf.add(tf.subtract(pos_dist,neg_dist),alpha)\n",
        "  #通过取带零的最大值和对训练样本的求和来计算整个公式\n",
        "  loss = tf.reduce_sum(tf.maximum(basic_loss,0))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mVhERFIbTvj"
      },
      "source": [
        "def create_train_model(model,alpha):\n",
        "  y_pred=[]\n",
        "  anchor_input = Input(inputshape) \n",
        "  positive_input = Input(inputshape)\n",
        "  negative_input = Input(inputshape)\n",
        "  anchor_out = Model(anchor_input, model(anchor_input))\n",
        "  positive_out = Model(positive_input, model(positive_input))\n",
        "  negative_out = Model(negative_input, model(negative_input))\n",
        "  y_pred.append(anchor_out.output)\n",
        "  y_pred.append(positive_out.output)\n",
        "  y_pred.append(negative_out.output)\n",
        "\n",
        "  loss = Lambda(lambda x: triplet_loss(x, alpha), output_shape=[1])(y_pred)\n",
        "  # y_true=np.zeros((total,3)).tolist() \n",
        "  # alpha=0.2\n",
        "  return Model(inputs = [anchor_input,positive_input,negative_input], outputs=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY3rlRWM_R56"
      },
      "source": [
        "def train_model(model):\n",
        "  tic = time.clock()\n",
        "  #抽三元组次数\n",
        "  num_times=1\n",
        "  mm=create_train_model(model, 0.2)\n",
        "  optm=K.optimizers.Adam(lr=1e-5)\n",
        "  mm.compile(optimizer=optm,loss=lambda t,p:p)\n",
        "  # model_checkpoint = ModelCheckpoint('/content/gdrive/MyDrive/CM', monitor=None, verbose=1, \n",
        "  #                                      save_best_only=True, save_weights_only=True,period=10)\n",
        "  for i in tqdm(range(num_times)):\n",
        "    hard_tri=process_triplet(X_pos,X_neg,model,num=num)\n",
        "    y_label=np.zeros((len(hard_tri),1))#y用不着\n",
        "    xx = [\n",
        "          hard_tri[:,0,:,:,:],\n",
        "          hard_tri[:,1,:,:,:],\n",
        "          hard_tri[:,2,:,:,:]\n",
        "    ]\n",
        "    mm.fit(x=xx,y=y_label,batch_size=5,epochs=500)\n",
        "  model.save('/content/gdrive/MyDrive/CM/temp.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWlwe84dfDx2"
      },
      "source": [
        "Smodel=SimpleNet(inputshape)\n",
        "mmodel=create_train_model(Smodel,alpha=alpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCbu4QBBC3ow"
      },
      "source": [
        "train_model(Smodel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK-MAKF1AWYM"
      },
      "source": [
        "unlabeled_path='/content/gdrive/MyDrive/CM/unlabeled_patches/unlabeled_X.npy'\n",
        "weight_='/content/gdrive/MyDrive/CM/temp.h5'\n",
        "unlabeled_pool=np.load(unlabeled_path)\n",
        "Smodel.load_weights(weight_)\n",
        "positive_embed=embedding(X_pos,Smodel)\n",
        "negative_embed=embedding(X_neg,Smodel)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhwgElacWTLm"
      },
      "source": [
        "#半监督部分\n",
        "#mixup获取伪标签\n",
        "scale=200#每次抽取的无标签数量\n",
        "topk=25\n",
        "def mixup(p_embed,n_embed,unlabeled,model,scale=scale):\n",
        "  Smodel.load_weights(weight_)\n",
        "  #随机从无标签池中抽取样本\n",
        "  temp_unlabeled=sampling(unlabeled,scale)\n",
        "  #开始mixup\n",
        "  count_all_label=[]\n",
        "  for i in tqdm(range(len(temp_unlabeled))):\n",
        "    data_enhanced=np.zeros((7,11,11,7))\n",
        "    data_enhanced[0,]=unlabeled[i,]\n",
        "    #水平垂直对角翻转\n",
        "    data_enhanced[1,]=np.flip(unlabeled[i,],axis=0)\n",
        "    data_enhanced[2,]=np.flip(unlabeled[i,],axis=1)\n",
        "    data_enhanced[3,]=np.flip(unlabeled[i,],axis=2)\n",
        "    #增加噪声(轻噪，重噪)\n",
        "    noise = np.random.normal(0.0, 0.01, size=unlabeled[i,].shape)\n",
        "    data_enhanced[4,]=i+noise\n",
        "    noise = np.random.normal(0.0, 0.05, size=unlabeled[i,].shape)\n",
        "    data_enhanced[5,]=i+noise\n",
        "    #随机旋转\n",
        "    k = np.random.randint(4)\n",
        "    data_enhanced[6,]=np.rot90(unlabeled[i,],k=k)\n",
        "    #增强结果的embed\n",
        "    enhance_embed=embedding(data_enhanced,model)\n",
        "    #计算度量获取伪标签\n",
        "    pseudo_label=[]\n",
        "    for j in range(len(enhance_embed)):\n",
        "      #扩充向量维度，计算距离，找最小距离\n",
        "      dis_list=[]\n",
        "      #计算正样本池\n",
        "      temp=np.repeat(enhance_embed[j,].reshape((1,-1)), p_embed.shape[0], axis=0)\n",
        "      temp_dis_mat=np.sum((temp-p_embed)*(temp-p_embed),axis=1)\n",
        "      temp_p_dis=np.min(temp_dis_mat) \n",
        "      #计算负样本池\n",
        "      temp=np.repeat(enhance_embed[j,].reshape((1,-1)), n_embed.shape[0], axis=0)\n",
        "      temp_dis_mat=np.sum((temp-n_embed)*(temp-n_embed),axis=1)\n",
        "      temp_n_dis=np.min(temp_dis_mat)\n",
        "      #伪样本标签获取\n",
        "      dis_list.append(temp_n_dis)\n",
        "      dis_list.append(temp_p_dis)\n",
        "      label = dis_list.index(min(dis_list))      \n",
        "      pseudo_label.append(label)\n",
        "    counts = np.bincount(pseudo_label)\n",
        "    plabel= np.argmax(counts)\n",
        "    acc=counts[plabel]/len(pseudo_label)\n",
        "    count_all_label.append((plabel,acc))\n",
        "\n",
        "  #返回batch所有无标签样本和对应伪标签及概率\n",
        "  return temp_unlabeled,count_all_label\n",
        "#获取pseudo triplet\n",
        "def ranking(unlabeled_sample,prob,topk=topk):\n",
        "  \"\"\"\n",
        "  unlabeled_sample:batchsize的抽样无标签样本\n",
        "  prob:对应伪标签和概率\n",
        "  \"\"\"\n",
        "  #类别分开放\n",
        "  p_pseudo_list=[]\n",
        "  n_pseudo_list=[]\n",
        "  pof200_list=[]\n",
        "  nof200_list=[]\n",
        "  for i in range(len(prob)):\n",
        "    if prob[i][0]==1:\n",
        "      p_pseudo_list.append(prob[i])\n",
        "      pof200_list.append(unlabeled_sample[i,].tolist())\n",
        "    else:\n",
        "      n_pseudo_list.append(prob[i])\n",
        "      nof200_list.append(unlabeled_sample[i,].tolist())\n",
        "  p_pseudo_array=np.asarray(p_pseudo_list)\n",
        "  n_pseudo_array=np.asarray(n_pseudo_list)\n",
        "  pof200_array=np.asarray(pof200_list)\n",
        "  nof200_array=np.asarray(nof200_list)\n",
        "  #按置信度排序\n",
        "  p_rank=np.argsort(p_pseudo_array[:,1],axis=0)\n",
        "  n_rank=np.argsort(n_pseudo_array[:,1],axis=0)\n",
        "  #分类样本\n",
        "  last_pos=[]\n",
        "  last_neg=[]\n",
        "  for i in range(topk):\n",
        "    last_pos.append(pof200_array[p_rank[i]].tolist())\n",
        "    last_neg.append(nof200_array[n_rank[i]].tolist())\n",
        "  last_pos=np.asarray(last_pos)\n",
        "  last_neg=np.asarray(last_neg)\n",
        "  #返回mixup获得的置信度前25的伪标签样本作为伪标签样本池\n",
        "  return last_pos,last_neg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPUXGS1sJrlU",
        "outputId": "cd1b999e-5fef-4f3e-b863-2a45b422fab5"
      },
      "source": [
        "unlabeled_batch,class_prob=mixup(positive_embed,negative_embed,unlabeled_pool,Smodel,scale=scale)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [00:07<00:00, 28.38it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQcqUtj-XrCd"
      },
      "source": [
        "pseudo_pos,pseudo_neg=ranking(unlabeled_batch,class_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS1nEHwHeoAX",
        "outputId": "de6f9f93-7757-4d82-e29e-ec6e48123160"
      },
      "source": [
        "pseudo_hard_tri=process_triplet(pseudo_pos,pseudo_neg,Smodel,num=10)#伪样本池出10*2个困难三元组，降低权重"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "构建正例样本困难三元组\n",
            "构建负例样本困难三元组\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNNKgM5NfNd0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}